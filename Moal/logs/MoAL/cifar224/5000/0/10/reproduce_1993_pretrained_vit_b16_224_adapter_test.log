2025-11-04 10:31:48,602 [trainer.py] => config: exps/Moal_cifar224.json
2025-11-04 10:31:48,602 [trainer.py] => prefix: reproduce
2025-11-04 10:31:48,602 [trainer.py] => dataset: cifar224
2025-11-04 10:31:48,602 [trainer.py] => memory_size: 0
2025-11-04 10:31:48,602 [trainer.py] => memory_per_class: 0
2025-11-04 10:31:48,602 [trainer.py] => fixed_memory: False
2025-11-04 10:31:48,602 [trainer.py] => shuffle: True
2025-11-04 10:31:48,602 [trainer.py] => init_cls: 10
2025-11-04 10:31:48,602 [trainer.py] => increment: 10
2025-11-04 10:31:48,602 [trainer.py] => model_name: MoAL
2025-11-04 10:31:48,602 [trainer.py] => backbone_type: pretrained_vit_b16_224_adapter
2025-11-04 10:31:48,602 [trainer.py] => device: [device(type='cuda', index=1)]
2025-11-04 10:31:48,602 [trainer.py] => seed: 1993
2025-11-04 10:31:48,602 [trainer.py] => Hidden: 5000
2025-11-04 10:31:48,602 [trainer.py] => rg: 0.1
2025-11-04 10:31:48,602 [trainer.py] => lambda_fkd: 1
2025-11-04 10:31:48,602 [trainer.py] => cali_weight: 1.0
2025-11-04 10:31:48,602 [trainer.py] => alpha: 0.999
2025-11-04 10:31:48,602 [trainer.py] => tuned_epoch: 80
2025-11-04 10:31:48,602 [trainer.py] => progreesive_epoch: 80
2025-11-04 10:31:48,602 [trainer.py] => init_lr: 0.01
2025-11-04 10:31:48,602 [trainer.py] => progressive_lr: 0.01
2025-11-04 10:31:48,602 [trainer.py] => batch_size: 48
2025-11-04 10:31:48,602 [trainer.py] => weight_decay: 0.0005
2025-11-04 10:31:48,602 [trainer.py] => min_lr: 0
2025-11-04 10:31:48,602 [trainer.py] => ffn_num: 64
2025-11-04 10:31:48,602 [trainer.py] => optimizer: sgd
2025-11-04 10:31:48,602 [trainer.py] => vpt_type: shallow
2025-11-04 10:31:48,602 [trainer.py] => prompt_token_num: 5
2025-11-04 10:47:33,720 [trainer.py] => config: exps/Moal_cifar224.json
2025-11-04 10:47:33,720 [trainer.py] => prefix: reproduce
2025-11-04 10:47:33,720 [trainer.py] => dataset: cifar224
2025-11-04 10:47:33,720 [trainer.py] => memory_size: 0
2025-11-04 10:47:33,720 [trainer.py] => memory_per_class: 0
2025-11-04 10:47:33,720 [trainer.py] => fixed_memory: False
2025-11-04 10:47:33,720 [trainer.py] => shuffle: True
2025-11-04 10:47:33,720 [trainer.py] => init_cls: 10
2025-11-04 10:47:33,720 [trainer.py] => increment: 10
2025-11-04 10:47:33,721 [trainer.py] => model_name: MoAL
2025-11-04 10:47:33,721 [trainer.py] => backbone_type: pretrained_vit_b16_224_adapter
2025-11-04 10:47:33,721 [trainer.py] => device: [device(type='cuda', index=1)]
2025-11-04 10:47:33,721 [trainer.py] => seed: 1993
2025-11-04 10:47:33,721 [trainer.py] => Hidden: 5000
2025-11-04 10:47:33,721 [trainer.py] => rg: 0.1
2025-11-04 10:47:33,721 [trainer.py] => lambda_fkd: 1
2025-11-04 10:47:33,721 [trainer.py] => cali_weight: 1.0
2025-11-04 10:47:33,721 [trainer.py] => alpha: 0.999
2025-11-04 10:47:33,721 [trainer.py] => tuned_epoch: 80
2025-11-04 10:47:33,721 [trainer.py] => progreesive_epoch: 80
2025-11-04 10:47:33,721 [trainer.py] => init_lr: 0.01
2025-11-04 10:47:33,721 [trainer.py] => progressive_lr: 0.01
2025-11-04 10:47:33,721 [trainer.py] => batch_size: 48
2025-11-04 10:47:33,721 [trainer.py] => weight_decay: 0.0005
2025-11-04 10:47:33,721 [trainer.py] => min_lr: 0
2025-11-04 10:47:33,721 [trainer.py] => ffn_num: 64
2025-11-04 10:47:33,721 [trainer.py] => optimizer: sgd
2025-11-04 10:47:33,721 [trainer.py] => vpt_type: shallow
2025-11-04 10:47:33,721 [trainer.py] => prompt_token_num: 5
2025-11-04 10:47:54,407 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-04 10:48:15,044 [trainer.py] => config: exps/Moal_cifar224.json
2025-11-04 10:48:15,044 [trainer.py] => prefix: reproduce
2025-11-04 10:48:15,044 [trainer.py] => dataset: cifar224
2025-11-04 10:48:15,044 [trainer.py] => memory_size: 0
2025-11-04 10:48:15,044 [trainer.py] => memory_per_class: 0
2025-11-04 10:48:15,044 [trainer.py] => fixed_memory: False
2025-11-04 10:48:15,044 [trainer.py] => shuffle: True
2025-11-04 10:48:15,044 [trainer.py] => init_cls: 10
2025-11-04 10:48:15,044 [trainer.py] => increment: 10
2025-11-04 10:48:15,044 [trainer.py] => model_name: MoAL
2025-11-04 10:48:15,044 [trainer.py] => backbone_type: pretrained_vit_b16_224_adapter
2025-11-04 10:48:15,044 [trainer.py] => device: [device(type='cuda', index=1)]
2025-11-04 10:48:15,044 [trainer.py] => seed: 1993
2025-11-04 10:48:15,044 [trainer.py] => Hidden: 5000
2025-11-04 10:48:15,044 [trainer.py] => rg: 0.1
2025-11-04 10:48:15,044 [trainer.py] => lambda_fkd: 1
2025-11-04 10:48:15,044 [trainer.py] => cali_weight: 1.0
2025-11-04 10:48:15,044 [trainer.py] => alpha: 0.999
2025-11-04 10:48:15,044 [trainer.py] => tuned_epoch: 80
2025-11-04 10:48:15,044 [trainer.py] => progreesive_epoch: 80
2025-11-04 10:48:15,044 [trainer.py] => init_lr: 0.01
2025-11-04 10:48:15,044 [trainer.py] => progressive_lr: 0.01
2025-11-04 10:48:15,044 [trainer.py] => batch_size: 48
2025-11-04 10:48:15,044 [trainer.py] => weight_decay: 0.0005
2025-11-04 10:48:15,044 [trainer.py] => min_lr: 0
2025-11-04 10:48:15,044 [trainer.py] => ffn_num: 64
2025-11-04 10:48:15,045 [trainer.py] => optimizer: sgd
2025-11-04 10:48:15,045 [trainer.py] => vpt_type: shallow
2025-11-04 10:48:15,045 [trainer.py] => prompt_token_num: 5
2025-11-04 10:48:16,253 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-04 11:03:08,135 [trainer.py] => config: exps/Moal_cifar224.json
2025-11-04 11:03:08,136 [trainer.py] => prefix: reproduce
2025-11-04 11:03:08,136 [trainer.py] => dataset: cifar224
2025-11-04 11:03:08,136 [trainer.py] => memory_size: 0
2025-11-04 11:03:08,136 [trainer.py] => memory_per_class: 0
2025-11-04 11:03:08,136 [trainer.py] => fixed_memory: False
2025-11-04 11:03:08,136 [trainer.py] => shuffle: True
2025-11-04 11:03:08,136 [trainer.py] => init_cls: 10
2025-11-04 11:03:08,136 [trainer.py] => increment: 10
2025-11-04 11:03:08,136 [trainer.py] => model_name: MoAL
2025-11-04 11:03:08,136 [trainer.py] => backbone_type: pretrained_vit_b16_224_adapter
2025-11-04 11:03:08,136 [trainer.py] => device: [device(type='cuda', index=1)]
2025-11-04 11:03:08,136 [trainer.py] => seed: 1993
2025-11-04 11:03:08,136 [trainer.py] => Hidden: 5000
2025-11-04 11:03:08,136 [trainer.py] => rg: 0.1
2025-11-04 11:03:08,136 [trainer.py] => lambda_fkd: 1
2025-11-04 11:03:08,136 [trainer.py] => cali_weight: 1.0
2025-11-04 11:03:08,136 [trainer.py] => alpha: 0.999
2025-11-04 11:03:08,136 [trainer.py] => tuned_epoch: 80
2025-11-04 11:03:08,136 [trainer.py] => progreesive_epoch: 80
2025-11-04 11:03:08,136 [trainer.py] => init_lr: 0.01
2025-11-04 11:03:08,136 [trainer.py] => progressive_lr: 0.01
2025-11-04 11:03:08,136 [trainer.py] => batch_size: 48
2025-11-04 11:03:08,136 [trainer.py] => weight_decay: 0.0005
2025-11-04 11:03:08,136 [trainer.py] => min_lr: 0
2025-11-04 11:03:08,136 [trainer.py] => ffn_num: 64
2025-11-04 11:03:08,136 [trainer.py] => optimizer: sgd
2025-11-04 11:03:08,136 [trainer.py] => vpt_type: shallow
2025-11-04 11:03:08,136 [trainer.py] => prompt_token_num: 5
2025-11-04 11:03:09,343 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2025-11-04 11:03:09,624 [trainer.py] => All params: 0
2025-11-04 11:03:09,624 [trainer.py] => Trainable params: 0
